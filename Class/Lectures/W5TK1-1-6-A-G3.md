
# Lecture Notes: AI-Aided Project Framework & Generative AI Tools

## Part 1: Course Philosophy and AI Agent Architecture

### The Role of AI Agents in Education
**Utilize** the **AI** as a **class assistant** and a **personal agent** initialized for your **education**.

**Instantiate** this **agent** independently using your own **AI model**.

**Focus** on **closed technologies** or models like **Microsoft Copilot** or **Google Gemini** to prevent **data scattering**.

**Avoid** uploading **transcripts** or **private data** to external **models** unless **installed locally**.

**Adopt** the **current era** by **engaging agents** wherever possible.

**Create** your own **agent** in parallel with **classes** to **support** your **learning process**.

**Design** a **primary agent** that acts as your **digital alter ego**.

**Configure** the **main agent** to **manage sub-agents** responsible for **specific subjects** or **tasks**.

**Establish** a **hierarchy** where the **alter ego** discusses **philosophy** and **education strategy**, while **sub-agents** execute **specific tasks**.

**Use** the **main agent** to **prepare prompts** for **subordinate agents**.

**Implement** this **structure** similar to **class structures** in **object-oriented programming**.

**Define** a **super-class** for **general learning strategies** and **sub-classes** for **specific subjects**.

**Manage** the **context window** efficiently, as **memory** assigned to each **agent** is **limited**.

**Avoid duplicating content** across **agents** to **optimize memory usage**.

**Delegate** specific **tasks** constructed in the **parent agent** to **agents** associated with **specific subjects**.

### The "Corporate" Metaphor for AI Interaction
**Simulate** a **corporate structure** where **AI agents** act as **employees** and you act as the **CEO**.

**Build** large **structures** and **manage** them through **interaction** with **agents**.

**Focus** on **achieving goals** and **verifying effects** rather than micromanaging every **internal process**.

**Understand** that **managers** in a **corporation** do not know every detail but check if **tasks** are **completed** on **time**.

**Trust** the **AI agents** to perform **complex internal tasks**, similar to using **programming libraries**.

**Program** the **AI** using **natural language** to **describe problems** and **desired outputs**.

**Treat** the **AI agent** as a massive **library** that **implements** almost everything.

**Scale** your **operations** to create a **global corporation** structure single-handedly using **AI resources**.

### Project Goals and Mindset
**Define** a **semester project** related to **AI**, **Virtual Reality**, or **Extended Reality (XR)**.

**Align** the **project** with your **vision** of your **future self** and **career goals**.

**Practice** **delayed gratification** by investing **effort** now to **achieve** a future **vision**.

**Consult** your **AI assistant** to **decide** on the **project scope** and **requirements**.

**Delegate** "black work" or **tedious tasks** (like documentation) to the **AI** to **maximize efficiency**.

**Adopt** a **philosophy** of **intelligent laziness**: doing things **well** without **unnecessary manual effort**.

**Increase** your **productivity** by **running multiple agents** to handle **different aspects** or **multiple projects**.

**Combine** your **interests** (e.g., electronics) with **new technologies** and **AI**.

**Document** the **process** and **project realization** using **AI tools**.

**Aim** to **set goals** that are slightly **beyond** your current **capabilities** to **mobilize development**.

## Part 2: Development Environment Setup

### Directory Structure
**Create** a **directory** named **W5** on your **C drive**.

**Create** a **subdirectory** named **TK1** inside **W5**.

**Create** a **folder** using your **Felix account identifier** (or login) inside **TK1**.

**Use** this **structure** to **organize** all **class-related materials** and **projects**.

**Create** a **folder** named **Progs** inside **W5** to store **software** like **ComfyUI**.

### GitHub Configuration
**Create** a **GitHub account** if you do not have one.

**Consider** using a **student email** to access **GitHub Copilot** licenses.

**Install** **Git** for **Windows** (64-bit setup) if not present.

**Verify** **Git installation** by opening a **command prompt** (`CMD`) in your **directory** and typing `git`.

**Create** a **private repository** on **GitHub** named after your **Felix identifier**.

**Initialize** the **repository** with a **README** and a **Python .gitignore** file.

**Clone** your **repository** to your **local directory** using the `git clone [URL]` command.

**Use** the **green code button** on **GitHub** to **copy** the correct **HTTPS URL**.

**Authenticate** using `gh auth login` in the **terminal** if **credential errors** occur.

**Add** the **instructor** (user `wuzart`) as a **collaborator** in **repository settings**.

### Visual Studio Code Setup
**Install** **Visual Studio Code Insiders** version.

**Log in** to **VS Code** using your **GitHub account** via the **Accounts** icon.

**Turn on** **Settings Sync** to **backup** your **configuration**.

**Open** your **cloned repository** folder as a **Project** in **VS Code**.

**Trust** the **folder** when prompted by **VS Code**.

### Version Control Workflow
**Understand** the **difference** between **Save** (`Ctrl+S`), **Commit**, and **Sync**.

**Save** only **updates** the **file** on the **local disk**.

**Commit** **registers** the **changes** in the **version control system** locally.

**Provide** a **commit message** to **explain** the **changes**.

**Sync** (or **Push**) **transfers** the **local commits** to the **remote GitHub repository**.

**Use** `git pull` to **retrieve** the **latest changes** from the **remote server** to your **local machine**.

**Edit** the `README.md` file using **Markdown** syntax to **practice**.

**Use** **Markdown** for **documentation** as it is easily **versioned** and **understood** by **AI**.

## Part 3: Advanced Project Management & Meta-Structures

### Integrating External Knowledge (Instructor's Repo)
**Clone** the **instructor's repository** into a **subdirectory** (e.g., `x_repos`) within your **project**.

**Add** the **name** of the **instructor's repository** to your `.gitignore` file.

**Ensure** the **external repository** is **ignored** by your **version control** to prevent **tracking conflicts**.

**Treat** this **external repository** as a **read-only module** of **intelligence** or **context**.

**Update** the **external repository** periodically using `git pull` inside its **directory**.

**Use** this **structure** to **inject context** (lecture notes, schemas) into your **AI agents**.

### Managing AI Context and Personality
**Recognize** that **changing models** (e.g., Gemini 2.5 to 3.0) causes **personality drift**.

**Audit** your **project context** when **upgrading models**, as **interpretations** of **prompts** may change.

**Understand** that **newer models** might interpret **metaphors** (e.g., "Mozart's symphony") more **literally**.

**Adjust** **prompts** to ensure **professional technical interpretation** rather than **poetic output**.

**Use** **keywords** and **triggers** to **direct** the **model's attention** to specific **memory blocks**.

**Structure** your **prompts** to include **meta-level management** instructions.

**Load** specific **context files** (like `AI_Persona_Student_CEO_Context`) into the **AI chat** to **initialize** the **agent**.

### Organization and Teams
**Create** an **organization** and **teams** on **GitHub** for **class management**.

**Accept** **invitations** to join the **class team** to access **shared resources**.

**Maintain** a **professional workflow** by **logging out** of accounts after **lab sessions**.

## Part 4: Generative AI with ComfyUI

### Installation and Hardware
**Download** the **ComfyUI Windows Portable** version.

**Use** **7-Zip** to **extract** the **compressed archive**.

**Move** the **extracted folder** to `W5/Progs`.

**Run** `run_nvidia_gpu.bat` if the **computer** has an **Nvidia GPU**.

**Run** `run_cpu.bat` if using a **computer** without a dedicated **GPU**.

### Interface and Basic Workflow
**Access** the **ComfyUI interface** via the **web browser** that opens automatically.

**Observe** the **console window** for **errors** and **process execution logs**.

**Load** the **default workflow** to **test** the **installation**.

**Download** missing **models** (Checkpoints) if flagged by the **interface**.

**Place** downloaded **models** into `ComfyUI/models/checkpoints`.

**Refresh** the **interface** using the **Refresh** button or `Ctrl+R` to **detect new models**.

**Queue Prompt** (Run) to **generate** an **image**.

### Advanced Configuration and Nodes
**Install** the **ComfyUI Manager** by **cloning** its **repository** into `custom_nodes`.

**Use** the **Manager** to **install** missing **nodes** easily.

**Understand** the **node structure**: **Load Checkpoint** -> **Positive/Negative Prompt** -> **KSampler** -> **VAE Decode**.

**Use** **ControlNet** nodes to **guide** generation based on **poses** or **outlines**.

**Download** **ControlNet models** and place them in `models/controlnet`.

**Connect** the **ControlNet** to the **workflow** to **constrain** the **output**.

### Generating 3D Assets
**Focus** on **generating 3D models** for **VR** or **game environments**.

**Select** a **Checkpoint** (e.g., Stable Diffusion 1.5 based) that handles **3D aspects** well.

**Search** for **models** on platforms like **Civitai** filtering for **Checkpoints**.

**Use** **Loras** to **add specific styles** or **details** to the **base model**.

**Construct** a **prompt** describing a **full-body character** in a **T-pose** or **A-pose**.

**Fix** the **Seed** to **fixed** to **iterate** on the **same image** while **tweaking parameters**.

**Use** an **Upscaler** node to **increase resolution** and **detail** before **3D conversion**.

**Generate** the **3D mesh** from the **2D image** using specific **3D processing nodes**.

### Post-Processing
**Export** the **generated 3D model** (e.g., .glb format).

**Import** the **model** into **Blender** for **inspection** and **modification**.

**Remove** the **background** plane if generated.

**Optimize** the **mesh** for **use** in **applications** like **VRChat**.
